{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5611bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import gzip\n",
    "import re\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "\n",
    "class StressCoarseGrainer:\n",
    "    \"\"\"\n",
    "    Goldhirsch-Weinhart stress coarse-graining for granular materials\n",
    "    Includes kinetic and virial (contact) contributions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, folder_path, pattern='Dump.shear_fixed_Load_1wall.*', \n",
    "                 max_frames=np.inf):\n",
    "        self.folder_path = Path(folder_path)\n",
    "        self.pattern = pattern\n",
    "        self.max_frames = max_frames\n",
    "        \n",
    "        # Particle type densities (kg/m³)\n",
    "        self.type_density = {1: 2600.0, 2: 2600.0, 3: 2600.0}\n",
    "        \n",
    "        # Coarse-graining parameters\n",
    "        self.w = None  # Auto-estimated\n",
    "        self.support_fac = 3.0  # For Gaussian, this is ~3 standard deviations\n",
    "        self.kernel_type = 'gaussian'  # Default to Gaussian\n",
    "        \n",
    "        print(f\"Initializing Stress Coarse-Grainer (Goldhirsch-Weinhart)\")\n",
    "        print(f\"  Kernel type: Gaussian\")\n",
    "        print(f\"  Support factor: {self.support_fac}\")\n",
    "        \n",
    "    def gaussian_kernel(self, r, w):\n",
    "        \"\"\"\n",
    "        Gaussian kernel function (normalized for 3D)\n",
    "        φ(r) = (1/(√(2π)w)³) exp(-r²/(2w²))\n",
    "        \"\"\"\n",
    "        norm = 1.0 / ((np.sqrt(2 * np.pi) * w)**3)\n",
    "        return norm * np.exp(-r**2 / (2 * w**2))\n",
    "    \n",
    "    def gaussian_kernel_gradient(self, r_vec, w):\n",
    "        \"\"\"\n",
    "        Gradient of Gaussian kernel: ∇φ(r)\n",
    "        ∇φ = -(r_vec/w²) * φ(r)\n",
    "        Returns: gradient vector for each point\n",
    "        \"\"\"\n",
    "        r = np.linalg.norm(r_vec, axis=-1, keepdims=True)\n",
    "        \n",
    "        # Compute kernel value\n",
    "        kernel_val = self.gaussian_kernel(r.squeeze(), w)\n",
    "        \n",
    "        # ∇φ = -(r_vec/w²) * φ(r)\n",
    "        grad = -(r_vec / (w**2)) * kernel_val[..., None]\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    def find_and_sort_files(self):\n",
    "        \"\"\"Find and sort LAMMPS dump files\"\"\"\n",
    "        print(f\"Looking for files in: {self.folder_path}\")\n",
    "        \n",
    "        if not self.folder_path.exists():\n",
    "            raise FileNotFoundError(f\"Folder does not exist: {self.folder_path}\")\n",
    "            \n",
    "        files = list(self.folder_path.glob(self.pattern))\n",
    "        if not files:\n",
    "            raise FileNotFoundError(f\"No files found matching pattern: {self.pattern}\")\n",
    "            \n",
    "        print(f\"Found {len(files)} files matching pattern\")\n",
    "        \n",
    "        # Extract and sort by timestep\n",
    "        timesteps = []\n",
    "        valid_files = []\n",
    "        patterns = [r'\\.(\\d+)$', r'\\.(\\d+)\\.gz$', r'\\.(\\d+)\\..*$', \n",
    "                   r'wall\\.(\\d+)', r'_(\\d+)$', r'(\\d+)$']\n",
    "        \n",
    "        for file in files:\n",
    "            timestep = None\n",
    "            for pattern in patterns:\n",
    "                match = re.search(pattern, file.name)\n",
    "                if match:\n",
    "                    timestep = int(match.group(1))\n",
    "                    break\n",
    "            if timestep is not None:\n",
    "                timesteps.append(timestep)\n",
    "                valid_files.append(file)\n",
    "                \n",
    "        if not valid_files:\n",
    "            raise ValueError(\"No files with extractable timesteps found\")\n",
    "            \n",
    "        sorted_indices = np.argsort(timesteps)\n",
    "        self.files = [valid_files[i] for i in sorted_indices]\n",
    "        self.timesteps = [timesteps[i] for i in sorted_indices]\n",
    "        \n",
    "        print(f\"Processing {len(self.files)} files\")\n",
    "        return self.files[:int(self.max_frames)]\n",
    "    \n",
    "    def read_lammps_dump_with_contacts(self, filename):\n",
    "        \"\"\"\n",
    "        Read LAMMPS dump file with contact/pair interaction data\n",
    "        Expected format includes particle data and pair force data\n",
    "        \"\"\"\n",
    "        filepath = Path(filename)\n",
    "        opener = gzip.open if filepath.suffix == '.gz' else open\n",
    "        \n",
    "        with opener(filepath, 'rt') as f:\n",
    "            # Read timestep\n",
    "            line = f.readline()\n",
    "            if not line.startswith('ITEM: TIMESTEP'):\n",
    "                raise ValueError(f\"Expected TIMESTEP header\")\n",
    "            timestep = int(f.readline().strip())\n",
    "            \n",
    "            # Read number of atoms\n",
    "            line = f.readline()\n",
    "            if not line.startswith('ITEM: NUMBER OF ATOMS'):\n",
    "                raise ValueError(f\"Expected NUMBER OF ATOMS header\")\n",
    "            N = int(f.readline().strip())\n",
    "            \n",
    "            # Read box bounds\n",
    "            line = f.readline()\n",
    "            if not line.startswith('ITEM: BOX BOUNDS'):\n",
    "                raise ValueError(f\"Expected BOX BOUNDS header\")\n",
    "            \n",
    "            boundary_types = line.split()[3:6] if len(line.split()) > 3 else ['pp', 'pp', 'pp']\n",
    "            \n",
    "            bounds = []\n",
    "            for _ in range(3):\n",
    "                line = f.readline().strip()\n",
    "                if line.startswith('ITEM:'):\n",
    "                    break\n",
    "                vals = list(map(float, line.split()))\n",
    "                if len(vals) >= 2:\n",
    "                    bounds.append(vals[:2])\n",
    "                    \n",
    "            bounds = np.array(bounds)\n",
    "            dim = len(bounds)\n",
    "            \n",
    "            # Read atoms section\n",
    "            if not line.startswith('ITEM: ATOMS'):\n",
    "                line = f.readline()\n",
    "            \n",
    "            cols = line.split()[2:]\n",
    "            \n",
    "            # Read particle data\n",
    "            data = []\n",
    "            for _ in range(N):\n",
    "                line = f.readline().strip()\n",
    "                if line:\n",
    "                    data.append(list(map(float, line.split())))\n",
    "                    \n",
    "            data = np.array(data)\n",
    "        \n",
    "        # Parse particle data\n",
    "        frame = {\n",
    "            'timestep': timestep,\n",
    "            'N': N,\n",
    "            'box_bounds': bounds,\n",
    "            'boundary_types': boundary_types,\n",
    "            'dim': dim,\n",
    "            'x': np.zeros((N, max(2, dim))),\n",
    "            'v': np.zeros((N, max(2, dim))),\n",
    "            'type': np.ones(N, dtype=int),\n",
    "            'radius': np.ones(N) * 0.005,\n",
    "            'mass': None,\n",
    "            'id': None,\n",
    "            'contacts': []  # List of contact interactions\n",
    "        }\n",
    "        \n",
    "        # Map columns\n",
    "        id_col = None\n",
    "        for i, col in enumerate(cols):\n",
    "            col = col.lower()\n",
    "            if col == 'id':\n",
    "                frame['id'] = data[:, i].astype(int)\n",
    "                id_col = i\n",
    "            elif col == 'type':\n",
    "                frame['type'] = data[:, i].astype(int)\n",
    "            elif col in ['x', 'xu']:\n",
    "                frame['x'][:, 0] = data[:, i]\n",
    "            elif col in ['y', 'yu']:\n",
    "                frame['x'][:, 1] = data[:, i]\n",
    "            elif col in ['z', 'zu'] and dim >= 3:\n",
    "                frame['x'][:, 2] = data[:, i]\n",
    "            elif col == 'vx':\n",
    "                frame['v'][:, 0] = data[:, i]\n",
    "            elif col == 'vy':\n",
    "                frame['v'][:, 1] = data[:, i]\n",
    "            elif col == 'vz' and dim >= 3:\n",
    "                frame['v'][:, 2] = data[:, i]\n",
    "            elif col in ['radius', 'r']:\n",
    "                frame['radius'] = data[:, i]\n",
    "            elif col in ['mass', 'm']:\n",
    "                frame['mass'] = data[:, i]\n",
    "        \n",
    "        # Check if we need to read a separate contact file\n",
    "        # For now, we'll generate synthetic contacts from neighbor data\n",
    "        # In practice, you would read from a separate dump.contact file\n",
    "        \n",
    "        print(f\"    Timestep {timestep}: {N} particles\")\n",
    "        print(f\"    Box: [{bounds[0,0]:.3f}, {bounds[0,1]:.3f}] x \"\n",
    "              f\"[{bounds[1,0]:.3f}, {bounds[1,1]:.3f}] x [{bounds[2,0]:.3f}, {bounds[2,1]:.3f}]\")\n",
    "        \n",
    "        return frame\n",
    "    \n",
    "    def detect_contacts(self, frame, contact_cutoff=None):\n",
    "        \"\"\"\n",
    "        Detect particle contacts and estimate contact forces\n",
    "        In practice, these should come from LAMMPS compute pair/local\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        frame : dict\n",
    "            Frame data\n",
    "        contact_cutoff : float\n",
    "            Distance threshold for contact (default: sum of radii)\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        contacts : list of dict\n",
    "            Each contact: {'i': id_i, 'j': id_j, 'r_ij': vector, 'f_ij': force_vector}\n",
    "        \"\"\"\n",
    "        positions = frame['x'][:, :frame['dim']]\n",
    "        radii = frame['radius']\n",
    "        \n",
    "        if contact_cutoff is None:\n",
    "            contact_cutoff = 2.0 * np.mean(radii) * 1.01  # Small gap tolerance\n",
    "        \n",
    "        tree = cKDTree(positions)\n",
    "        contacts = []\n",
    "        \n",
    "        # Find all pairs within contact distance\n",
    "        pairs = tree.query_pairs(contact_cutoff, output_type='ndarray')\n",
    "        \n",
    "        print(f\"    Detecting contacts (cutoff={contact_cutoff:.6f})...\")\n",
    "        print(f\"    Found {len(pairs)} potential contacts\")\n",
    "        \n",
    "        for pair in pairs:\n",
    "            i, j = pair\n",
    "            r_ij = positions[j] - positions[i]\n",
    "            dist = np.linalg.norm(r_ij)\n",
    "            overlap = (radii[i] + radii[j]) - dist\n",
    "            \n",
    "            if overlap > 0:  # Actual contact\n",
    "                # Estimate normal force (simplified Hertzian contact)\n",
    "                # In practice, read from LAMMPS output\n",
    "                k_n = 1e5  # Normal stiffness (adjust based on simulation)\n",
    "                f_mag = k_n * overlap**1.5\n",
    "                f_ij = f_mag * r_ij / (dist + 1e-12)  # Normal force\n",
    "                \n",
    "                contacts.append({\n",
    "                    'i': i,\n",
    "                    'j': j,\n",
    "                    'r_ij': r_ij,\n",
    "                    'f_ij': f_ij\n",
    "                })\n",
    "        \n",
    "        print(f\"    Contacts with overlap: {len(contacts)}\")\n",
    "        frame['contacts'] = contacts\n",
    "        return contacts\n",
    "    \n",
    "    def read_contact_file(self, contact_filename, frame):\n",
    "        \"\"\"\n",
    "        Read contact data from LAMMPS pair/local output\n",
    "        Expected format: atom_i atom_j fx fy fz x y z (contact point)\n",
    "        \n",
    "        This is a placeholder - adapt to your actual contact file format\n",
    "        \"\"\"\n",
    "        # TODO: Implement based on your specific contact file format\n",
    "        # For now, use detect_contacts as fallback\n",
    "        pass\n",
    "    \n",
    "    def compute_particle_mass(self, frame):\n",
    "        \"\"\"Compute particle masses\"\"\"\n",
    "        if frame['mass'] is not None:\n",
    "            return frame['mass']\n",
    "        \n",
    "        volume = (4.0/3.0) * np.pi * frame['radius']**3\n",
    "        mass = np.array([volume[i] * self.type_density.get(frame['type'][i], 2600.0) \n",
    "                        for i in range(frame['N'])])\n",
    "        return mass\n",
    "    \n",
    "    def estimate_coarse_graining_width(self, frame):\n",
    "        \"\"\"Estimate coarse-graining width from particle spacing\"\"\"\n",
    "        positions = frame['x'][:, :frame['dim']]\n",
    "        n_sample = min(1000, len(positions))\n",
    "        sample_idx = np.random.choice(len(positions), n_sample, replace=False)\n",
    "        \n",
    "        tree = cKDTree(positions)\n",
    "        distances, _ = tree.query(positions[sample_idx], k=2)\n",
    "        avg_spacing = np.mean(distances[:, 1])\n",
    "        \n",
    "        w = 2.5 * avg_spacing\n",
    "        \n",
    "        print(f\"Estimated coarse-graining parameters:\")\n",
    "        print(f\"  Average spacing: {avg_spacing:.6f}\")\n",
    "        print(f\"  Width (w): {w:.6f}\")\n",
    "        print(f\"  Support: {self.support_fac * w:.6f}\")\n",
    "        \n",
    "        return w\n",
    "    \n",
    "    def coarse_grain_stress(self, frame, grid_points, w=None):\n",
    "        \"\"\"\n",
    "        Coarse-grain stress tensor using Goldhirsch-Weinhart method with Gaussian kernel\n",
    "        \n",
    "        σ(r) = σ^kin(r) + σ^vir(r)\n",
    "        \n",
    "        Kinetic part: σ^kin = Σ_i m_i (v_i - v(r)) ⊗ (v_i - v(r)) φ(|r - r_i|)\n",
    "        Virial part: σ^vir = -1/2 Σ_contacts f_ij ⊗ r_ij ∫_0^1 φ(|r - r_i - s*r_ij|) ds\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        frame : dict\n",
    "            Frame data with particles and contacts\n",
    "        grid_points : ndarray\n",
    "            Grid points for evaluation\n",
    "        w : float\n",
    "            Coarse-graining width\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        stress_field : ndarray (N_grid x 3 x 3)\n",
    "            Stress tensor at each grid point\n",
    "        stress_kinetic : ndarray (N_grid x 3 x 3)\n",
    "            Kinetic contribution\n",
    "        stress_virial : ndarray (N_grid x 3 x 3)\n",
    "            Virial (contact) contribution\n",
    "        \"\"\"\n",
    "        if w is None:\n",
    "            w = self.estimate_coarse_graining_width(frame)\n",
    "        \n",
    "        support = self.support_fac * w\n",
    "        \n",
    "        positions = frame['x'][:, :frame['dim']]\n",
    "        velocities = frame['v'][:, :frame['dim']]\n",
    "        mass = self.compute_particle_mass(frame)\n",
    "        contacts = frame.get('contacts', [])\n",
    "        \n",
    "        # First compute velocity field for fluctuation calculation\n",
    "        print(\"Computing velocity field for stress calculation...\")\n",
    "        velocity_field = self._compute_velocity_field(frame, grid_points, w)\n",
    "        \n",
    "        n_grid = len(grid_points)\n",
    "        dim = frame['dim']\n",
    "        \n",
    "        stress_kinetic = np.zeros((n_grid, 3, 3))\n",
    "        stress_virial = np.zeros((n_grid, 3, 3))\n",
    "        \n",
    "        tree = cKDTree(positions)\n",
    "        \n",
    "        print(f\"Computing stress at {n_grid} grid points...\")\n",
    "        \n",
    "        # Kinetic stress contribution\n",
    "        for i, grid_pt in enumerate(grid_points):\n",
    "            if i % 1000 == 0:\n",
    "                print(f\"  Progress: {i}/{n_grid} points\")\n",
    "            \n",
    "            # Find particles within support\n",
    "            indices = tree.query_ball_point(grid_pt[:dim], support)\n",
    "            \n",
    "            if not indices:\n",
    "                continue\n",
    "            \n",
    "            # Compute kinetic stress\n",
    "            for idx in indices:\n",
    "                r_vec = positions[idx] - grid_pt[:dim]\n",
    "                r = np.linalg.norm(r_vec)\n",
    "                \n",
    "                if r < support:\n",
    "                    kernel_val = self.gaussian_kernel(np.array([r]), w)[0]\n",
    "                    \n",
    "                    # Velocity fluctuation\n",
    "                    v_fluct = velocities[idx] - velocity_field[i, :dim]\n",
    "                    \n",
    "                    # σ^kin = m * v_fluct ⊗ v_fluct * φ\n",
    "                    stress_kinetic[i, :dim, :dim] += mass[idx] * np.outer(v_fluct, v_fluct) * kernel_val\n",
    "        \n",
    "        # Virial stress contribution from contacts\n",
    "        print(f\"Computing virial stress from {len(contacts)} contacts...\")\n",
    "        \n",
    "        n_quad = 10  # Quadrature points for line integral\n",
    "        quad_points = np.linspace(0, 1, n_quad)\n",
    "        \n",
    "        for contact in contacts:\n",
    "            i_p = contact['i']\n",
    "            j_p = contact['j']\n",
    "            r_ij = contact['r_ij']\n",
    "            f_ij = contact['f_ij']\n",
    "            \n",
    "            # Line integral along contact\n",
    "            for s in quad_points:\n",
    "                r_contact = positions[i_p] + s * r_ij\n",
    "                \n",
    "                # Find grid points within support of this contact point\n",
    "                dists = np.linalg.norm(grid_points[:, :dim] - r_contact, axis=1)\n",
    "                mask = dists < support\n",
    "                \n",
    "                if np.any(mask):\n",
    "                    kernel_vals = self.gaussian_kernel(dists[mask], w)\n",
    "                    \n",
    "                    # σ^vir = -1/2 * f_ij ⊗ r_ij * φ * ds\n",
    "                    virial_contrib = -0.5 * np.outer(f_ij[:dim], r_ij[:dim]) * (1.0 / n_quad)\n",
    "                    \n",
    "                    for grid_idx in np.where(mask)[0]:\n",
    "                        stress_virial[grid_idx, :dim, :dim] += virial_contrib * kernel_vals[grid_idx - np.where(mask)[0][0]]\n",
    "        \n",
    "        # Total stress\n",
    "        stress_field = stress_kinetic + stress_virial\n",
    "        \n",
    "        print(\"  ✓ Stress computation complete\")\n",
    "        \n",
    "        return stress_field, stress_kinetic, stress_virial\n",
    "    \n",
    "    def _compute_velocity_field(self, frame, grid_points, w):\n",
    "        \"\"\"Helper: compute velocity field for kinetic stress\"\"\"\n",
    "        positions = frame['x'][:, :frame['dim']]\n",
    "        velocities = frame['v'][:, :frame['dim']]\n",
    "        mass = self.compute_particle_mass(frame)\n",
    "        support = self.support_fac * w\n",
    "        \n",
    "        tree = cKDTree(positions)\n",
    "        n_grid = len(grid_points)\n",
    "        dim = frame['dim']\n",
    "        velocity_field = np.zeros((n_grid, dim))\n",
    "        \n",
    "        for i, grid_pt in enumerate(grid_points):\n",
    "            indices = tree.query_ball_point(grid_pt[:dim], support)\n",
    "            \n",
    "            if not indices:\n",
    "                continue\n",
    "            \n",
    "            r_vec = positions[indices] - grid_pt[:dim]\n",
    "            r = np.linalg.norm(r_vec, axis=1)\n",
    "            weights = self.gaussian_kernel(r, w) * mass[indices]\n",
    "            \n",
    "            total_weight = np.sum(weights)\n",
    "            if total_weight > 1e-12:\n",
    "                velocity_field[i] = np.sum(weights[:, None] * velocities[indices], axis=0) / total_weight\n",
    "        \n",
    "        return velocity_field\n",
    "    \n",
    "    def create_grid(self, frame, n_points=None, dx=None):\n",
    "        \"\"\"Create grid for coarse-graining\"\"\"\n",
    "        bounds = frame['box_bounds']\n",
    "        dim = frame['dim']\n",
    "        \n",
    "        if n_points is None and dx is None:\n",
    "            w = self.estimate_coarse_graining_width(frame)\n",
    "            dx = w / 2.0\n",
    "            print(f\"Using grid spacing: {dx:.6f}\")\n",
    "        \n",
    "        if n_points is None:\n",
    "            if np.isscalar(dx):\n",
    "                dx = np.array([dx] * dim)\n",
    "            n_points = tuple(int((bounds[i, 1] - bounds[i, 0]) / dx[i]) for i in range(dim))\n",
    "        \n",
    "        if isinstance(n_points, int):\n",
    "            n_points = tuple([n_points] * dim)\n",
    "        \n",
    "        if dim == 2:\n",
    "            x = np.linspace(bounds[0, 0], bounds[0, 1], n_points[0])\n",
    "            y = np.linspace(bounds[1, 0], bounds[1, 1], n_points[1])\n",
    "            xx, yy = np.meshgrid(x, y)\n",
    "            grid_points = np.column_stack([xx.ravel(), yy.ravel()])\n",
    "            grid_shape = (n_points[1], n_points[0])\n",
    "        else:\n",
    "            x = np.linspace(bounds[0, 0], bounds[0, 1], n_points[0])\n",
    "            y = np.linspace(bounds[1, 0], bounds[1, 1], n_points[1])\n",
    "            z = np.linspace(bounds[2, 0], bounds[2, 1], n_points[2])\n",
    "            xx, yy, zz = np.meshgrid(x, y, z, indexing='ij')\n",
    "            grid_points = np.column_stack([xx.ravel(), yy.ravel(), zz.ravel()])\n",
    "            grid_shape = n_points\n",
    "        \n",
    "        print(f\"Created grid: {n_points} points\")\n",
    "        return grid_points, grid_shape\n",
    "    \n",
    "    def plot_stress_field(self, frame, stress_field, grid_points, grid_shape, \n",
    "                         component='xx', slice_dim=None, slice_val=None):\n",
    "        \"\"\"\n",
    "        Plot stress field component\n",
    "        \n",
    "        Components: 'xx', 'yy', 'zz', 'xy', 'xz', 'yz'\n",
    "        \"\"\"\n",
    "        comp_map = {\n",
    "            'xx': (0, 0), 'yy': (1, 1), 'zz': (2, 2),\n",
    "            'xy': (0, 1), 'yx': (1, 0),\n",
    "            'xz': (0, 2), 'zx': (2, 0),\n",
    "            'yz': (1, 2), 'zy': (2, 1)\n",
    "        }\n",
    "        \n",
    "        i, j = comp_map[component.lower()]\n",
    "        stress_comp = stress_field[:, i, j]\n",
    "        \n",
    "        dim = frame['dim']\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        if dim == 2:\n",
    "            stress_grid = stress_comp.reshape(grid_shape)\n",
    "            vmax = np.percentile(np.abs(stress_comp[stress_comp != 0]), 95)\n",
    "            im = ax.imshow(stress_grid, \n",
    "                          extent=[frame['box_bounds'][0, 0], frame['box_bounds'][0, 1],\n",
    "                                 frame['box_bounds'][1, 0], frame['box_bounds'][1, 1]],\n",
    "                          origin='lower', cmap='RdBu_r', aspect='auto',\n",
    "                          vmin=-vmax, vmax=vmax)\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('y')\n",
    "        else:\n",
    "            # 3D - show slice or scatter\n",
    "            if slice_dim is not None and slice_val is not None:\n",
    "                w = self.estimate_coarse_graining_width(frame)\n",
    "                mask = np.abs(grid_points[:, slice_dim] - slice_val) < w\n",
    "                scatter = ax.scatter(grid_points[mask, 0], grid_points[mask, 1],\n",
    "                                   c=stress_comp[mask], s=30, cmap='RdBu_r')\n",
    "                plt.colorbar(scatter, ax=ax, label=f'σ_{component}')\n",
    "            else:\n",
    "                scatter = ax.scatter(grid_points[:, 0], grid_points[:, 1],\n",
    "                                   c=stress_comp, s=20, cmap='RdBu_r', alpha=0.6)\n",
    "                plt.colorbar(scatter, ax=ax, label=f'σ_{component}')\n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('y')\n",
    "        \n",
    "        if dim == 2:\n",
    "            plt.colorbar(im, ax=ax, label=f'σ_{component}')\n",
    "        \n",
    "        ax.set_title(f'Stress Field Component σ_{component} (Timestep {frame[\"timestep\"]})')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return fig\n",
    "    \n",
    "    def plot_stress_comparison(self, frame, stress_total, stress_kinetic, stress_virial,\n",
    "                              grid_points, grid_shape, component='xx'):\n",
    "        \"\"\"Compare kinetic and virial stress contributions\"\"\"\n",
    "        comp_map = {\n",
    "            'xx': (0, 0), 'yy': (1, 1), 'zz': (2, 2),\n",
    "            'xy': (0, 1), 'xz': (0, 2), 'yz': (1, 2)\n",
    "        }\n",
    "        \n",
    "        i, j = comp_map[component.lower()]\n",
    "        \n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "        \n",
    "        components = [\n",
    "            (stress_kinetic[:, i, j], 'Kinetic'),\n",
    "            (stress_virial[:, i, j], 'Virial'),\n",
    "            (stress_total[:, i, j], 'Total')\n",
    "        ]\n",
    "        \n",
    "        for ax, (stress_comp, title) in zip(axes, components):\n",
    "            if frame['dim'] == 2:\n",
    "                stress_grid = stress_comp.reshape(grid_shape)\n",
    "                vmax = np.percentile(np.abs(stress_comp[stress_comp != 0]), 95)\n",
    "                im = ax.imshow(stress_grid,\n",
    "                             extent=[frame['box_bounds'][0, 0], frame['box_bounds'][0, 1],\n",
    "                                    frame['box_bounds'][1, 0], frame['box_bounds'][1, 1]],\n",
    "                             origin='lower', cmap='RdBu_r', aspect='auto',\n",
    "                             vmin=-vmax, vmax=vmax)\n",
    "                plt.colorbar(im, ax=ax, label=f'σ_{component}')\n",
    "            \n",
    "            ax.set_xlabel('x')\n",
    "            ax.set_ylabel('y')\n",
    "            ax.set_title(f'{title} Stress σ_{component}')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        return fig\n",
    "    \n",
    "    def read_all_frames(self):\n",
    "        \"\"\"Read all dump files\"\"\"\n",
    "        files = self.find_and_sort_files()\n",
    "        frames = []\n",
    "        \n",
    "        for i, file in enumerate(files):\n",
    "            print(f\"\\nReading file {i+1}/{len(files)}: {file.name}\")\n",
    "            try:\n",
    "                frame = self.read_lammps_dump_with_contacts(file)\n",
    "                \n",
    "                # Detect contacts (or read from separate file)\n",
    "                self.detect_contacts(frame)\n",
    "                \n",
    "                frames.append(frame)\n",
    "                print(f\"  ✓ Success\")\n",
    "            except Exception as e:\n",
    "                print(f\"  ✗ Error: {str(e)}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        if not frames:\n",
    "            raise RuntimeError(\"No frames successfully read\")\n",
    "        \n",
    "        print(f\"\\n✓ Successfully read {len(frames)} frames\")\n",
    "        self.frames = frames\n",
    "        return frames\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize\n",
    "    cg = StressCoarseGrainer(\n",
    "        folder_path=r\"F:\\DATA_constant_volume_DEM\\DATA_constant_volume\\vf578_vt0.23\",\n",
    "        pattern=\"Dump.shear_fixed_Load_1wall.*\",\n",
    "        max_frames=3  # Start with a few frames for testing\n",
    "    )\n",
    "    \n",
    "    # Read frames\n",
    "    frames = cg.read_all_frames()\n",
    "    \n",
    "    # Select frame with flow\n",
    "    frame_idx = -1\n",
    "    for i, f in enumerate(frames):\n",
    "        v_max = np.max(np.abs(f['v']))\n",
    "        if v_max > 0.01:\n",
    "            frame_idx = i\n",
    "            break\n",
    "    if frame_idx == -1:\n",
    "        frame_idx = len(frames) - 1\n",
    "    \n",
    "    frame = frames[frame_idx]\n",
    "    print(f\"\\n=== Analyzing frame {frame_idx} (timestep {frame['timestep']}) ===\")\n",
    "    \n",
    "    # Create grid\n",
    "    print(\"\\n=== Creating grid ===\")\n",
    "    grid_points, grid_shape = cg.create_grid(frame, n_points=30)  # Coarser for speed\n",
    "    \n",
    "    # Compute stress field\n",
    "    print(\"\\n=== Computing stress field ===\")\n",
    "    stress_total, stress_kin, stress_vir = cg.coarse_grain_stress(\n",
    "        frame, grid_points\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nStress statistics:\")\n",
    "    print(f\"  Kinetic σ_xx: [{np.min(stress_kin[:,0,0]):.3e}, {np.max(stress_kin[:,0,0]):.3e}]\")\n",
    "    print(f\"  Virial σ_xx: [{np.min(stress_vir[:,0,0]):.3e}, {np.max(stress_vir[:,0,0]):.3e}]\")\n",
    "    print(f\"  Total σ_xx: [{np.min(stress_total[:,0,0]):.3e}, {np.max(stress_total[:,0,0]):.3e}]\")\n",
    "    \n",
    "    # Plot stress fields\n",
    "    print(\"\\n=== Plotting stress fields ===\")\n",
    "    \n",
    "    # Plot individual components\n",
    "    fig1 = cg.plot_stress_field(frame, stress_total, grid_points, grid_shape, \n",
    "                                component='xx')\n",
    "    \n",
    "    fig2 = cg.plot_stress_field(frame, stress_total, grid_points, grid_shape,\n",
    "                                component='xy')\n",
    "    \n",
    "    # Compare contributions\n",
    "    fig3 = cg.plot_stress_comparison(frame, stress_total, stress_kin, stress_vir,\n",
    "                                     grid_points, grid_shape, component='xx')\n",
    "    \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
